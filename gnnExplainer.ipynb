{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5da1d35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "841e55e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import Data, Batch\n",
    "from torch_geometric.utils import to_networkx\n",
    "from torch_geometric.explain import Explainer, ModelConfig\n",
    "from torch_geometric.explain.algorithm import GNNExplainer\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "# Your model defs must match training-time classes\n",
    "# from your_models import GCNNet, GATNet\n",
    "# Assuming they were defined as GCNNet(in_dim) and GATNet(in_dim)\n",
    "# and output logits of shape [num_graphs, num_classes] for graph classification.\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Keep the same label order you used in training:\n",
    "label_order = [\"Benign\", \"InSitu\", \"Invasive\",  \"Normal\"]  # <-- change if different\n",
    "num_classes = len(label_order)\n",
    "ckpt_dir = \"checkpoints\"  # where you saved them\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5bbc0bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, GATv2Conv, global_mean_pool\n",
    "\n",
    "class GCNNet(nn.Module):\n",
    "    def __init__(self, in_dim, hidden=64, num_classes=4, dropout=0.3):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(in_dim, hidden)\n",
    "        self.conv2 = GCNConv(hidden, hidden)\n",
    "        self.lin = nn.Linear(hidden, num_classes)\n",
    "        self.dropout = dropout\n",
    "    def forward(self, data):\n",
    "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = F.relu(self.conv2(x, edge_index))\n",
    "        x = global_mean_pool(x, batch)\n",
    "        return self.lin(x)\n",
    "\n",
    "class GATNet(nn.Module):\n",
    "    def __init__(self, in_dim, hidden=32, heads=4, num_classes=4, dropout=0.3):\n",
    "        super().__init__()\n",
    "        self.gat1 = GATv2Conv(in_dim, hidden, heads=heads, dropout=dropout)\n",
    "        self.gat2 = GATv2Conv(hidden*heads, hidden, heads=1, dropout=dropout)\n",
    "        self.lin = nn.Linear(hidden, num_classes)\n",
    "        self.dropout = dropout\n",
    "    def forward(self, data):\n",
    "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
    "        x = F.elu(self.gat1(x, edge_index))\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = F.elu(self.gat2(x, edge_index))\n",
    "        x = global_mean_pool(x, batch)\n",
    "        return self.lin(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b127f5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: GCN GAT\n"
     ]
    }
   ],
   "source": [
    "# 2) Load checkpoints -> models\n",
    "def load_model(ckpt_path):\n",
    "    ckpt = torch.load(ckpt_path, map_location='cpu')\n",
    "    arch, in_dim, state = ckpt['arch'], ckpt['in_dim'], ckpt['state_dict']\n",
    "    if arch == 'GCN':\n",
    "        model = GCNNet(in_dim)\n",
    "    elif arch == 'GAT':\n",
    "        model = GATNet(in_dim)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown arch: {arch}\")\n",
    "    model.load_state_dict(state)\n",
    "    model.to(device).eval()\n",
    "    return arch, model\n",
    "\n",
    "gcn_arch, gcn_model = load_model(os.path.join(ckpt_dir, \"GCN_best.pth\"))\n",
    "gat_arch, gat_model = load_model(os.path.join(ckpt_dir, \"GAT_best.pth\"))\n",
    "print(\"Loaded:\", gcn_arch, gat_arch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a699ac74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GATNet(\n",
      "  (gat1): GATv2Conv(768, 32, heads=4)\n",
      "  (gat2): GATv2Conv(128, 32, heads=1)\n",
      "  (lin): Linear(in_features=32, out_features=4, bias=True)\n",
      ")\n",
      "GCNNet(\n",
      "  (conv1): GCNConv(768, 64)\n",
      "  (conv2): GCNConv(64, 64)\n",
      "  (lin): Linear(in_features=64, out_features=4, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(gat_model)\n",
    "print(gcn_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2090135e",
   "metadata": {},
   "source": [
    "# Load saved graphs and run predictions\n",
    "\n",
    "We'll now:\n",
    "1. Point to the `graphs_delaunay` directory containing saved `.pt` graph objects.\n",
    "2. Select a small sample of graph files (you can adjust the pattern/limit).\n",
    "3. Load them as `torch_geometric.data.Data` objects.\n",
    "4. Batch them and obtain logits & softmax probabilities from both GCN and GAT models.\n",
    "5. Display top predicted label (with probability) for each graph.\n",
    "\n",
    "You can later adjust `sample_limit` or specify explicit filenames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "501bc93c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 374 graph files.\n",
      "Using files:\n",
      " - iv008.pt\n",
      " - iv009.pt\n",
      " - iv010.pt\n",
      " - iv011.pt\n",
      " - iv012.pt\n",
      " - iv013.pt\n",
      " - iv015.pt\n",
      " - iv016.pt\n",
      "Loaded 8 graphs.\n",
      "Unique feature dims in sample: {768}\n",
      "DataBatch(x=[125, 768], edge_index=[2, 580], edge_attr=[580], pos=[125, 2], y=[8], batch=[125], ptr=[9])\n",
      "GCN logits shape: torch.Size([8, 4]) GAT logits shape: torch.Size([8, 4])\n",
      "[2, 2, 2, 2, 2, 2, 2, 2]\n",
      "Predictions per graph (index: GCN_label(prob) | GAT_label(prob)):\n",
      "Graph 0: Invasive (1.000) | Invasive (1.000)\n",
      "Graph 1: Invasive (1.000) | Invasive (1.000)\n",
      "Graph 2: Invasive (1.000) | Invasive (1.000)\n",
      "Graph 3: Invasive (1.000) | Invasive (1.000)\n",
      "Graph 4: Invasive (1.000) | Invasive (0.999)\n",
      "Graph 5: Invasive (1.000) | Invasive (0.999)\n",
      "Graph 6: Invasive (1.000) | Invasive (1.000)\n",
      "Graph 7: Invasive (0.999) | Invasive (0.997)\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "from typing import List\n",
    "\n",
    "# Directory with graphs (.pt). Adjust if different.\n",
    "graphs_dir = \"graphs_delaunay\"\n",
    "assert os.path.isdir(graphs_dir), f\"Directory not found: {graphs_dir} (adjust path)\"\n",
    "\n",
    "# Collect .pt files (excluding ones that may not be graph Data objects if needed)\n",
    "all_graph_files = sorted(glob.glob(os.path.join(graphs_dir, '*.pt')))\n",
    "print(f\"Found {len(all_graph_files)} graph files.\")\n",
    "\n",
    "# Limit sample for speed (adjust or set to None for all)\n",
    "sample_limit = 8  # change as needed\n",
    "sample_files = all_graph_files[200:200+sample_limit]\n",
    "print(\"Using files:\")\n",
    "for f in sample_files:\n",
    "    print(\" -\", os.path.basename(f))\n",
    "\n",
    "loaded_graphs: List[Data] = []\n",
    "for path in sample_files:\n",
    "    obj = torch.load(path, map_location='cpu', weights_only=False)  # removed weights_only for broader compatibility\n",
    "    # Expect either a Data object or a dict with 'data'\n",
    "    if isinstance(obj, Data):\n",
    "        data_obj = obj\n",
    "    elif isinstance(obj, dict) and 'data' in obj and isinstance(obj['data'], Data):\n",
    "        data_obj = obj['data']\n",
    "    else:\n",
    "        raise TypeError(f\"Unsupported graph file format: {path}\")\n",
    "\n",
    "    # Ensure required attributes\n",
    "    if getattr(data_obj, 'x', None) is None or getattr(data_obj, 'edge_index', None) is None:\n",
    "        raise ValueError(f\"Graph {path} missing x or edge_index\")\n",
    "\n",
    "    # Add a dummy y if missing (not needed for inference but some utilities expect it)\n",
    "    if getattr(data_obj, 'y', None) is None:\n",
    "        data_obj.y = torch.tensor([-1])\n",
    "\n",
    "    loaded_graphs.append(data_obj)\n",
    "\n",
    "print(f\"Loaded {len(loaded_graphs)} graphs.\")\n",
    "\n",
    "# Sanity check feature dimension vs models\n",
    "in_dims = {g.x.size(-1) for g in loaded_graphs}\n",
    "print(\"Unique feature dims in sample:\", in_dims)\n",
    "\n",
    "# Create batch\n",
    "data_batch = Batch.from_data_list(loaded_graphs).to(device)\n",
    "print(data_batch)\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict(model, batch: Batch):\n",
    "    logits = model(batch)\n",
    "    probs = logits.softmax(dim=-1)\n",
    "    return logits, probs\n",
    "\n",
    "# Run both models\n",
    "logits_gcn, probs_gcn = predict(gcn_model, data_batch)\n",
    "logits_gat, probs_gat = predict(gat_model, data_batch)\n",
    "\n",
    "# Display predictions\n",
    "print(\"GCN logits shape:\", logits_gcn.shape, \"GAT logits shape:\", logits_gat.shape)\n",
    "\n",
    "pred_indices_gcn = probs_gcn.argmax(dim=-1).tolist()\n",
    "pred_indices_gat = probs_gat.argmax(dim=-1).tolist()\n",
    "print(pred_indices_gat)\n",
    "print(\"Predictions per graph (index: GCN_label(prob) | GAT_label(prob)):\")\n",
    "for i, (pi_gcn, pi_gat) in enumerate(zip(pred_indices_gcn, pred_indices_gat)):\n",
    "    label_gcn = label_order[pi_gcn] if pi_gcn < len(label_order) else f\"idx{pi_gcn}\"\n",
    "    label_gat = label_order[pi_gat] if pi_gat < len(label_order) else f\"idx{pi_gat}\"\n",
    "    prob_gcn = probs_gcn[i, pi_gcn].item()\n",
    "    prob_gat = probs_gat[i, pi_gat].item()\n",
    "    print(f\"Graph {i}: {label_gcn} ({prob_gcn:.3f}) | {label_gat} ({prob_gat:.3f})\")\n",
    "\n",
    "# Keep reference to batch + probabilities for later explanation steps\n",
    "current_batch = data_batch\n",
    "current_probs = { 'gcn': probs_gcn, 'gat': probs_gat }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e7730c7",
   "metadata": {},
   "source": [
    "# Define 4 batches of graphs and run GNNExplainer\n",
    "\n",
    "We'll construct four batches using index ranges over the already sorted `all_graph_files` list:\n",
    "- b1: indices 0–3\n",
    "- b2: indices 101–104\n",
    "- b3: indices 201–204\n",
    "- b4: indices 301–304\n",
    "\n",
    "Steps:\n",
    "1. Ensure `all_graph_files` exists (rebuild if notebook restarted).\n",
    "2. Load Data objects for each batch (skip if a file index is out of bounds).\n",
    "3. Pick one representative graph from each batch (default = first index).\n",
    "4. Predict with both models for those representative graphs.\n",
    "5. Run GNNExplainer (edge + node masks) for GCN and GAT separately.\n",
    "6. Visualize side‑by‑side: node coloration by node importance, edge width/color by edge importance.\n",
    "\n",
    "You can tweak:\n",
    "- `representative_choice` (choose 'first' or 'mid')\n",
    "- `explainer_epochs` for fidelity vs speed\n",
    "- `max_draw_nodes` to subsample large graphs for plotting only (explanations still run on full graph)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9359e71d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b1: loaded indices 0..3 (count=4)\n",
      "b2: loaded indices 101..104 (count=4)\n",
      "b3: loaded indices 201..204 (count=4)\n",
      "b4: loaded indices 301..304 (count=4)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "'multiclass' is not a valid ModelMode",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 70\u001b[0m\n\u001b[1;32m     64\u001b[0m representatives \u001b[38;5;241m=\u001b[39m {k: pick_representative(v[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdatas\u001b[39m\u001b[38;5;124m'\u001b[39m], representative_choice) \u001b[38;5;28;01mfor\u001b[39;00m k,v \u001b[38;5;129;01min\u001b[39;00m batches\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m     66\u001b[0m \u001b[38;5;66;03m# Build Explainers (reuse)\u001b[39;00m\n\u001b[1;32m     67\u001b[0m explainer_gcn \u001b[38;5;241m=\u001b[39m Explainer(\n\u001b[1;32m     68\u001b[0m     model\u001b[38;5;241m=\u001b[39mgcn_model,\n\u001b[1;32m     69\u001b[0m     algorithm\u001b[38;5;241m=\u001b[39mGNNExplainer(epochs\u001b[38;5;241m=\u001b[39mexplainer_epochs),\n\u001b[0;32m---> 70\u001b[0m     model_config\u001b[38;5;241m=\u001b[39m\u001b[43mModelConfig\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask_level\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgraph\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmulticlass\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlogits\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     71\u001b[0m )\n\u001b[1;32m     72\u001b[0m explainer_gat \u001b[38;5;241m=\u001b[39m Explainer(\n\u001b[1;32m     73\u001b[0m     model\u001b[38;5;241m=\u001b[39mgat_model,\n\u001b[1;32m     74\u001b[0m     algorithm\u001b[38;5;241m=\u001b[39mGNNExplainer(epochs\u001b[38;5;241m=\u001b[39mexplainer_epochs),\n\u001b[1;32m     75\u001b[0m     model_config\u001b[38;5;241m=\u001b[39mModelConfig(task_level\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgraph\u001b[39m\u001b[38;5;124m'\u001b[39m, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m'\u001b[39m, return_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlogits\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     76\u001b[0m )\n\u001b[1;32m     78\u001b[0m \u001b[38;5;66;03m# Visualization helpers\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/clam_latest/lib/python3.10/site-packages/torch_geometric/explain/config.py:155\u001b[0m, in \u001b[0;36mModelConfig.__init__\u001b[0;34m(self, mode, task_level, return_type)\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m    150\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    151\u001b[0m     mode: Union[ModelMode, \u001b[38;5;28mstr\u001b[39m],\n\u001b[1;32m    152\u001b[0m     task_level: Union[ModelTaskLevel, \u001b[38;5;28mstr\u001b[39m],\n\u001b[1;32m    153\u001b[0m     return_type: Optional[Union[ModelReturnType, \u001b[38;5;28mstr\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    154\u001b[0m ):\n\u001b[0;32m--> 155\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m=\u001b[39m \u001b[43mModelMode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    156\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtask_level \u001b[38;5;241m=\u001b[39m ModelTaskLevel(task_level)\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m return_type \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m==\u001b[39m ModelMode\u001b[38;5;241m.\u001b[39mregression:\n",
      "File \u001b[0;32m~/miniconda3/envs/clam_latest/lib/python3.10/enum.py:384\u001b[0m, in \u001b[0;36mEnumMeta.__call__\u001b[0;34m(cls, value, names, module, qualname, type, start)\u001b[0m\n\u001b[1;32m    359\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    360\u001b[0m \u001b[38;5;124;03mEither returns an existing member, or creates a new enum class.\u001b[39;00m\n\u001b[1;32m    361\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    381\u001b[0m \u001b[38;5;124;03m`type`, if set, will be mixed in as the first base class.\u001b[39;00m\n\u001b[1;32m    382\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    383\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m names \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:  \u001b[38;5;66;03m# simple value lookup\u001b[39;00m\n\u001b[0;32m--> 384\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__new__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    385\u001b[0m \u001b[38;5;66;03m# otherwise, functional API: we're creating a new Enum type\u001b[39;00m\n\u001b[1;32m    386\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_create_(\n\u001b[1;32m    387\u001b[0m         value,\n\u001b[1;32m    388\u001b[0m         names,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    392\u001b[0m         start\u001b[38;5;241m=\u001b[39mstart,\n\u001b[1;32m    393\u001b[0m         )\n",
      "File \u001b[0;32m~/miniconda3/envs/clam_latest/lib/python3.10/enum.py:701\u001b[0m, in \u001b[0;36mEnum.__new__\u001b[0;34m(cls, value)\u001b[0m\n\u001b[1;32m    699\u001b[0m ve_exc \u001b[38;5;241m=\u001b[39m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m is not a valid \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (value, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m))\n\u001b[1;32m    700\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m exc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 701\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ve_exc\n\u001b[1;32m    702\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m exc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    703\u001b[0m     exc \u001b[38;5;241m=\u001b[39m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    704\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124merror in \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m._missing_: returned \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m instead of None or a valid member\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    705\u001b[0m             \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, result)\n\u001b[1;32m    706\u001b[0m             )\n",
      "\u001b[0;31mValueError\u001b[0m: 'multiclass' is not a valid ModelMode"
     ]
    }
   ],
   "source": [
    "from math import floor\n",
    "from copy import deepcopy\n",
    "\n",
    "# Rebuild all_graph_files if not present (e.g., fresh kernel)\n",
    "if 'all_graph_files' not in globals():\n",
    "    import glob\n",
    "    graphs_dir = 'graphs_delaunay'\n",
    "    all_graph_files = sorted(glob.glob(os.path.join(graphs_dir, '*.pt')))\n",
    "    print(f\"Rebuilt list: {len(all_graph_files)} files\")\n",
    "\n",
    "# Batch definitions (inclusive ranges)\n",
    "batch_ranges = {\n",
    "    'b1': (0, 3),\n",
    "    'b2': (101, 104),\n",
    "    'b3': (201, 204),\n",
    "    'b4': (301, 304),\n",
    "}\n",
    "\n",
    "# Explainer / visualization parameters\n",
    "explainer_epochs = 40  # lowered for faster iteration; raise later if needed\n",
    "representative_choice = 'first'  # 'first' or 'mid'\n",
    "max_draw_nodes = 300  # if graph larger, we will still explain full but may prune for drawing\n",
    "\n",
    "# Helper: load a single graph Data object from index\n",
    "def load_graph_by_index(idx: int) -> Data:\n",
    "    if idx < 0 or idx >= len(all_graph_files):\n",
    "        raise IndexError(f\"Index {idx} out of bounds for {len(all_graph_files)} files\")\n",
    "    path = all_graph_files[idx]\n",
    "    obj = torch.load(path, map_location='cpu', weights_only=False)  # removed weights_only\n",
    "    if isinstance(obj, Data):\n",
    "        data_obj = obj\n",
    "    elif isinstance(obj, dict) and 'data' in obj and isinstance(obj['data'], Data):\n",
    "        data_obj = obj['data']\n",
    "    else:\n",
    "        raise TypeError(f\"Unsupported graph file at {path}\")\n",
    "    if getattr(data_obj, 'y', None) is None:\n",
    "        data_obj.y = torch.tensor([-1])\n",
    "    return data_obj\n",
    "\n",
    "# Prepare batches\n",
    "def build_batch(idx_range):\n",
    "    s, e = idx_range\n",
    "    valid_indices = [i for i in range(s, e+1) if i < len(all_graph_files)]\n",
    "    datas = [load_graph_by_index(i) for i in valid_indices]\n",
    "    batch = Batch.from_data_list(datas)\n",
    "    return valid_indices, datas, batch\n",
    "\n",
    "batches = {}\n",
    "for k, rng in batch_ranges.items():\n",
    "    try:\n",
    "        idxs, datas, batch = build_batch(rng)\n",
    "        batches[k] = {'indices': idxs, 'datas': datas, 'batch': batch}\n",
    "        print(f\"{k}: loaded indices {idxs[0]}..{idxs[-1]} (count={len(idxs)})\")\n",
    "    except Exception as ex:\n",
    "        print(f\"{k}: FAILED -> {ex}\")\n",
    "\n",
    "# Representative selection\n",
    "def pick_representative(datas, choice='first'):\n",
    "    if not datas: return None\n",
    "    if choice == 'mid':\n",
    "        return datas[len(datas)//2]\n",
    "    return datas[0]\n",
    "\n",
    "representatives = {k: pick_representative(v['datas'], representative_choice) for k,v in batches.items()}\n",
    "\n",
    "# Build Explainers (reuse)\n",
    "explainer_gcn = Explainer(\n",
    "    model=gcn_model,\n",
    "    algorithm=GNNExplainer(epochs=explainer_epochs),\n",
    "    model_config=ModelConfig(task_level='graph', mode='multiclass', return_type='logits')\n",
    ")\n",
    "explainer_gat = Explainer(\n",
    "    model=gat_model,\n",
    "    algorithm=GNNExplainer(epochs=explainer_epochs),\n",
    "    model_config=ModelConfig(task_level='graph', mode='multiclass', return_type='logits')\n",
    ")\n",
    "\n",
    "# Visualization helpers\n",
    "import matplotlib.colors as mcolors\n",
    "import numpy as np\n",
    "\n",
    "def visualize_explanation(data: Data, explanation, title: str, max_nodes=max_draw_nodes, create_figure=False):\n",
    "    data_cpu = data.cpu()\n",
    "    edge_index = data_cpu.edge_index\n",
    "    G = to_networkx(data_cpu, to_undirected=True)\n",
    "\n",
    "    # Node importance\n",
    "    node_mask = None\n",
    "    for attr_name in ['node_mask', 'node_imp', 'node_scores']:\n",
    "        if hasattr(explanation, attr_name) and getattr(explanation, attr_name) is not None:\n",
    "            node_mask = getattr(explanation, attr_name)\n",
    "            break\n",
    "    if node_mask is None:\n",
    "        node_mask = torch.ones(data_cpu.x.size(0))\n",
    "\n",
    "    # Edge importance\n",
    "    edge_mask = None\n",
    "    for attr_name in ['edge_mask', 'edge_imp', 'edge_scores']:\n",
    "        if hasattr(explanation, attr_name) and getattr(explanation, attr_name) is not None:\n",
    "            edge_mask = getattr(explanation, attr_name)\n",
    "            break\n",
    "    if edge_mask is None:\n",
    "        edge_mask = torch.ones(edge_index.size(1))\n",
    "\n",
    "    node_vals = node_mask.detach().cpu().numpy()\n",
    "    edge_vals = edge_mask.detach().cpu().numpy()\n",
    "\n",
    "    # Optional pruning for drawing\n",
    "    if G.number_of_nodes() > max_nodes:\n",
    "        k = max_nodes\n",
    "        top_idx = np.argsort(-node_vals)[:k]\n",
    "        keep = set(top_idx.tolist())\n",
    "        G = G.subgraph(keep).copy()\n",
    "        new_edge_vals = []\n",
    "        for ei, (u, v) in enumerate(edge_index.t().tolist()):\n",
    "            if u in keep and v in keep and G.has_edge(u, v):\n",
    "                new_edge_vals.append(edge_vals[ei])\n",
    "        edge_vals = np.array(new_edge_vals) if new_edge_vals else np.array([])\n",
    "        node_vals = node_vals[list(keep)]\n",
    "\n",
    "    cmap = plt.cm.viridis\n",
    "    norm = mcolors.Normalize(vmin=node_vals.min() if len(node_vals) else 0.0,\n",
    "                             vmax=node_vals.max() if len(node_vals) else 1.0)\n",
    "    pos = nx.spring_layout(G, seed=42)\n",
    "\n",
    "    if create_figure:\n",
    "        plt.figure(figsize=(4.5,4.5))\n",
    "\n",
    "    nx.draw_networkx_nodes(G, pos, node_size=120,\n",
    "                           node_color=[cmap(norm(node_vals[n])) if n < len(node_mask) else (0.5,0.5,0.5,1.0) for n in G.nodes()])\n",
    "\n",
    "    if len(edge_vals):\n",
    "        widths = []\n",
    "        colors = []\n",
    "        edge_iter = list(G.edges())\n",
    "        for idx_e, e in enumerate(edge_iter):\n",
    "            val = edge_vals[idx_e % len(edge_vals)] if len(edge_vals) else 1.0\n",
    "            widths.append(1.0 + 2.5 * (val / (edge_vals.max() + 1e-9)))\n",
    "            colors.append(cmap(norm(val)))\n",
    "        nx.draw_networkx_edges(G, pos, width=widths, edge_color=colors)\n",
    "    else:\n",
    "        nx.draw_networkx_edges(G, pos, width=1.0, edge_color='#999999')\n",
    "\n",
    "    nx.draw_networkx_labels(G, pos, font_size=6)\n",
    "    sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "    sm.set_array([])\n",
    "    plt.colorbar(sm, shrink=0.6)\n",
    "    plt.title(title)\n",
    "    plt.axis('off')\n",
    "\n",
    "# Run explanations for representatives\n",
    "rep_explanations = {}\n",
    "for tag, data_obj in representatives.items():\n",
    "    if data_obj is None:\n",
    "        print(f\"Skipping {tag}: no data\")\n",
    "        continue\n",
    "    data_obj = data_obj.to(device)\n",
    "    with torch.no_grad():\n",
    "        logits_gcn = gcn_model(Batch.from_data_list([data_obj]).to(device))\n",
    "        logits_gat = gat_model(Batch.from_data_list([data_obj]).to(device))\n",
    "        pred_gcn = logits_gcn.softmax(-1).argmax(-1).item()\n",
    "        pred_gat = logits_gat.softmax(-1).argmax(-1).item()\n",
    "    print(f\"Representative {tag}: GCN -> {label_order[pred_gcn]} | GAT -> {label_order[pred_gat]}\")\n",
    "\n",
    "    # Some PyG versions may not require / accept index for graph task; wrap in try\n",
    "    try:\n",
    "        explanation_gcn = explainer_gcn(data_obj, index=0)\n",
    "    except TypeError:\n",
    "        explanation_gcn = explainer_gcn(data_obj)\n",
    "    try:\n",
    "        explanation_gat = explainer_gat(data_obj, index=0)\n",
    "    except TypeError:\n",
    "        explanation_gat = explainer_gat(data_obj)\n",
    "\n",
    "    rep_explanations[tag] = {'gcn': explanation_gcn, 'gat': explanation_gat, 'data': data_obj.cpu()}\n",
    "\n",
    "    plt.figure(figsize=(9,4.8))\n",
    "    plt.subplot(1,2,1)\n",
    "    visualize_explanation(data_obj.cpu(), explanation_gcn, f\"{tag} - GCN\")\n",
    "    plt.subplot(1,2,2)\n",
    "    visualize_explanation(data_obj.cpu(), explanation_gat, f\"{tag} - GAT\")\n",
    "    plt.suptitle(f\"Representative {tag} explanations\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "print(\"Done generating explanations for representatives.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83716535",
   "metadata": {},
   "source": [
    "# Official PyG Explainer usage on current batch predictions\n",
    "\n",
    "Using PyG 2.5.2 Explainer API per docs:\n",
    "- Define a ModelConfig with `task_level='graph'`, `mode='multiclass'`, `return_type='logits'` (our models output raw logits).\n",
    "- Instantiate an `Explainer` wrapping each model with `GNNExplainer` algorithm.\n",
    "- For each graph in a Batch, obtain its predicted class and call `explainer(batch, index=i, target=predicted_class)`.\n",
    "- Collect node and edge masks (`explanation.node_mask`, `explanation.edge_mask`).\n",
    "\n",
    "Below we run this on the previously built `data_batch` (from the sample file subset) and store explanations in dictionaries for later analysis/visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9ee877ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explaining 8 graphs in current_batch\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Explainer.__init__() missing 1 required positional argument: 'explanation_type'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Build fresh Explainers following docs (in case previous ones differ)\u001b[39;00m\n\u001b[1;32m     10\u001b[0m model_config \u001b[38;5;241m=\u001b[39m ModelConfig(task_level\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgraph\u001b[39m\u001b[38;5;124m'\u001b[39m, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmulticlass_classification\u001b[39m\u001b[38;5;124m'\u001b[39m, return_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlog_probs\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 11\u001b[0m explainer_official_gcn \u001b[38;5;241m=\u001b[39m \u001b[43mExplainer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgcn_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malgorithm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mGNNExplainer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m60\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m explainer_official_gat \u001b[38;5;241m=\u001b[39m Explainer(model\u001b[38;5;241m=\u001b[39mgat_model, algorithm\u001b[38;5;241m=\u001b[39mGNNExplainer(epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m60\u001b[39m), model_config\u001b[38;5;241m=\u001b[39mmodel_config)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;129m@torch\u001b[39m\u001b[38;5;241m.\u001b[39mno_grad()\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpredict_logits\u001b[39m(model, batch):\n",
      "\u001b[0;31mTypeError\u001b[0m: Explainer.__init__() missing 1 required positional argument: 'explanation_type'"
     ]
    }
   ],
   "source": [
    "# Ensure we have a batch (reuse current_batch if available)\n",
    "if 'current_batch' not in globals():\n",
    "    raise RuntimeError(\"current_batch not found. Re-run the earlier cell that builds data_batch.\")\n",
    "\n",
    "batch_for_explain = current_batch.to(device)\n",
    "num_graphs = batch_for_explain.num_graphs\n",
    "print(f\"Explaining {num_graphs} graphs in current_batch\")\n",
    "\n",
    "# Build fresh Explainers following docs (in case previous ones differ)\n",
    "model_config = ModelConfig(task_level='graph', mode='multiclass_classification', return_type='log_probs')\n",
    "explainer_official_gcn = Explainer(model=gcn_model, algorithm=GNNExplainer(epochs=60), model_config=model_config)\n",
    "explainer_official_gat = Explainer(model=gat_model, algorithm=GNNExplainer(epochs=60), model_config=model_config)\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict_logits(model, batch):\n",
    "    return model(batch)\n",
    "\n",
    "logits_gcn_full = predict_logits(gcn_model, batch_for_explain)\n",
    "logits_gat_full = predict_logits(gat_model, batch_for_explain)\n",
    "probs_gcn_full = logits_gcn_full.softmax(-1)\n",
    "probs_gat_full = logits_gat_full.softmax(-1)\n",
    "preds_gcn_full = probs_gcn_full.argmax(-1).tolist()\n",
    "preds_gat_full = probs_gat_full.argmax(-1).tolist()\n",
    "\n",
    "print(\"GCN predictions:\")\n",
    "for i, cls in enumerate(preds_gcn_full):\n",
    "    print(f\"  graph {i}: {label_order[cls]} ({probs_gcn_full[i, cls].item():.3f})\")\n",
    "print(\"GAT predictions:\")\n",
    "for i, cls in enumerate(preds_gat_full):\n",
    "    print(f\"  graph {i}: {label_order[cls]} ({probs_gat_full[i, cls].item():.3f})\")\n",
    "\n",
    "# Run explanations; store results\n",
    "explanations_gcn = []\n",
    "explanations_gat = []\n",
    "for i in range(num_graphs):\n",
    "    target_gcn = preds_gcn_full[i]\n",
    "    target_gat = preds_gat_full[i]\n",
    "    # According to docs: explainer(batch, index=i, target=class_idx)\n",
    "    exp_gcn = explainer_official_gcn(batch_for_explain, index=i, target=target_gcn)\n",
    "    exp_gat = explainer_official_gat(batch_for_explain, index=i, target=target_gat)\n",
    "    explanations_gcn.append(exp_gcn)\n",
    "    explanations_gat.append(exp_gat)\n",
    "print(\"Collected explanations for all graphs.\")\n",
    "\n",
    "# Simple visualization of first graph explanation for each model using previously defined helper (if present)\n",
    "if 'visualize_explanation' in globals():\n",
    "    from torch_geometric.data import Batch as _Batch\n",
    "    # Extract single graph Data from batch (PyG Explanation has a subgraph property sometimes; we still use original)\n",
    "    # We rebuild from slice indices for clarity\n",
    "    first_graph_mask = (batch_for_explain.batch == 0)\n",
    "    data0 = Data(x=batch_for_explain.x[first_graph_mask].cpu(),\n",
    "                 edge_index=batch_for_explain.edge_index.clone().cpu())\n",
    "    plt.figure(figsize=(9,4.5))\n",
    "    plt.subplot(1,2,1)\n",
    "    visualize_explanation(data0, explanations_gcn[0], f\"Graph 0 GCN (target={label_order[preds_gcn_full[0]]})\", create_figure=False)\n",
    "    plt.subplot(1,2,2)\n",
    "    visualize_explanation(data0, explanations_gat[0], f\"Graph 0 GAT (target={label_order[preds_gat_full[0]]})\", create_figure=False)\n",
    "    plt.suptitle(\"First graph explanations (official API)\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"visualize_explanation helper not found; skipping quick plot.\")\n",
    "\n",
    "# Keep references for later analysis\n",
    "official_explanations = { 'gcn': explanations_gcn, 'gat': explanations_gat }\n",
    "print(\"Done.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clam_latest",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
